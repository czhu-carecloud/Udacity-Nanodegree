{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Validation Lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and some basic data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "X = pd.read_csv('titanic_data.csv')\n",
    "# Limit to numeric data\n",
    "X = X._get_numeric_data()\n",
    "# Separate the labels\n",
    "y = X['Survived']\n",
    "# Remove labels from the inputs, and age due to missing data\n",
    "del X['Age'], X['Survived']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing proper sklearn modules and splitting our data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Accuracy of prediciting itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Decision Tree has accuracy:  1.0\n",
      "GaussianNB has accuracy:  0.677890011223\n"
     ]
    }
   ],
   "source": [
    "# The decision tree classifier\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(X,y)\n",
    "print \"Decision Tree has accuracy: \",accuracy_score(y, clf1.predict(X))\n",
    "# The naive Bayes classifier\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(X,y)\n",
    "print \"GaussianNB has accuracy: \",accuracy_score(y, clf2.predict(X))\n",
    "\n",
    "answer = { \n",
    " \"Naive Bayes Score\": 0, \n",
    " \"Decision Tree Score\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Accuracy of training set models on test set predicitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree has accuracy:  0.647058823529\n",
      "GaussianNB has accuracy:  0.672268907563\n"
     ]
    }
   ],
   "source": [
    "# The decision tree classifier\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(X_train,y_train)\n",
    "print \"Decision Tree has accuracy: \",accuracy_score(y_test, clf1.predict(X_test))\n",
    "# The naive Bayes classifier\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(X_train,y_train)\n",
    "print \"GaussianNB has accuracy: \",accuracy_score(y_test, clf2.predict(X))\n",
    "\n",
    "answer = { \n",
    " \"Naive Bayes Score\": 0, \n",
    " \"Decision Tree Score\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Confusion matrix of training set models on test set predicitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for this Decision Tree:\n",
      "[[163  58]\n",
      " [ 66  70]]\n",
      "GaussianNB confusion matrix:\n",
      "[[163  58]\n",
      " [ 66  70]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(X_train,y_train)\n",
    "dt_cm = confusion_matrix(y_test,clf1.predict(X_test))\n",
    "print \"Confusion matrix for this Decision Tree:\\n\",dt_cm\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(X_train,y_train)\n",
    "nb_cm = confusion_matrix(y_test,clf1.predict(X_test))\n",
    "print \"GaussianNB confusion matrix:\\n\",nb_cm \n",
    "\n",
    "#TODO: store the confusion matrices on the test sets below\n",
    "\n",
    "confusions = {\n",
    " \"Naive Bayes\": nb_cm ,\n",
    " \"Decision Tree\": dt_cm\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Precision and Recall of traing set models on test set predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree recall: 0.49 and precision: 0.56\n",
      "GaussianNB recall: 0.38 and precision: 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import precision_score as precision\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(X_train, y_train)\n",
    "clf1_recall = recall(y_test,clf1.predict(X_test))\n",
    "clf1_precision = precision(y_test,clf1.predict(X_test))\n",
    "print \"Decision Tree recall: {:.2f} and precision: {:.2f}\".format(clf1_recall,clf1_precision)\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(X_train, y_train)\n",
    "clf2_recall = recall(y_test,clf2.predict(X_test))\n",
    "clf2_precision = precision(y_test,clf2.predict(X_test))\n",
    "print \"GaussianNB recall: {:.2f} and precision: {:.2f}\".format(clf2_recall,clf2_precision)\n",
    "\n",
    "results = {\n",
    "  \"Naive Bayes Recall\": clf2_recall,\n",
    "  \"Naive Bayes Precision\": clf2_precision,\n",
    "  \"Decision Tree Recall\": clf1_recall,\n",
    "  \"Decision Tree Precision\": clf1_recall\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. F1-score of training set models on test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree F1 score: 0.48\n",
      "GaussianNB F1 score: 0.45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(X_train, y_train)\n",
    "clf1_f1 = f1_score(y_test, clf1.predict(X_test))\n",
    "print \"Decision Tree F1 score: {:.2f}\".format(clf1_f1)\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(X_train, y_train)\n",
    "clf2_f1 = f1_score(y_test, clf2.predict(X_test))\n",
    "print \"GaussianNB F1 score: {:.2f}\".format(clf2_f1)\n",
    "\n",
    "F1_scores = {\n",
    " \"Naive Bayes\": clf2_f1,\n",
    " \"Decision Tree\": clf2_f1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. New imported dataset from sklearn for studying errors in linear regression. Finding the mean absolute error of predictions using a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree mean absolute error: 13.93\n",
      "Linear regression mean absolute error: 7.79\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "from sklearn.datasets import load_linnerud\n",
    "\n",
    "linnerud_data = load_linnerud()\n",
    "X = linnerud_data.data\n",
    "y = linnerud_data.target\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "reg1 = DecisionTreeRegressor()\n",
    "reg1.fit(X_train, y_train)\n",
    "dt_mae = mae(y_test,reg1.predict(X_test))\n",
    "print \"Decision Tree mean absolute error: {:.2f}\".format(dt_mae)\n",
    "\n",
    "reg2 = LinearRegression()\n",
    "reg2.fit(X_train, y_train)\n",
    "lr_mae= mae(y_test,reg2.predict(X_test))\n",
    "print \"Linear regression mean absolute error: {:.2f}\".format(lr_mae)\n",
    "\n",
    "results = {\n",
    " \"Linear Regression\": lr_mae,\n",
    " \"Decision Tree\": dt_mae\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree mean absolute error: 335.13\n",
      "Linear regression mean absolute error: 160.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "reg1 = DecisionTreeRegressor()\n",
    "reg1.fit(X_train, y_train)\n",
    "dt_mse = mse(y_test, reg1.predict(X_test))\n",
    "print \"Decision Tree mean absolute error: {:.2f}\".format(dt_mse)\n",
    "\n",
    "reg2 = LinearRegression()\n",
    "reg2.fit(X_train, y_train)\n",
    "lr_mse = mse(y_test, reg2.predict(X_test))\n",
    "print \"Linear regression mean absolute error: {:.2f}\".format(lr_mse)\n",
    "\n",
    "results = {\n",
    " \"Linear Regression\": lr_mse,\n",
    " \"Decision Tree\": dt_mse\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (gl-env)",
   "language": "python",
   "name": "gl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
